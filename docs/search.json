[
  {
    "objectID": "scripts/project/001-preprint_assertions.html",
    "href": "scripts/project/001-preprint_assertions.html",
    "title": "Recipe 001: Preprint Assertions",
    "section": "",
    "text": "This recipe measures lifecycle open science on OSF by looking at preprint assertions.\n\nWe define a lifecycle open research project as an Open OSF Preprint (see open-preprints) that meets the following criteria:\n\nHas at least 1 linked dataset via author assertion\nHas at least 1 linked preregistration via author assertion\n\n\n\nThe following table indicates the data features currently suported for this recipe.\nThe data can be segmented in a variety of ways, each of on the basis of one or more disaggregation methods.\n\nEach row in the table indicates the data features available for each segment/method combination (Segment, Disaggregation method).\nStructure incidates whether the data support cross-sectional (CS) or time-series cross-sectional (TSCS) analysis. In the case of TSCS data, Unit indicates the smallest level of disaggregation available (M for months).\nEfficiency indicates whether it is currently possible to calculate the proportion or share of research projects that meet the definition of lifecycle open science for each segment/method combination (Y for yes, N for no).\n\n\n\n\n\n\n\n\n\n\n\nSegment\nDisaggregation method\nStructure\nUnit\nEfficiency\n\n\n\n\nAggregate\n-\nTSCS\nM\nY\n\n\nOSFI\nDichotomous\n\n\n\n\n\nOSFI\nCategorical\n\n\n\n\n\nSubjects\nAggregate (parent subjects)\n\n\n\n\n\nSubjects\nDetailed (child subjects)\n\n\n\n\n\nProvider\nCategorical\n\n\n\n\n\nCreator demographics\nAge cohort"
  },
  {
    "objectID": "scripts/project/001-preprint_assertions.html#supported-features",
    "href": "scripts/project/001-preprint_assertions.html#supported-features",
    "title": "Recipe 001: Preprint Assertions",
    "section": "",
    "text": "The following table indicates the data features currently suported for this recipe.\nThe data can be segmented in a variety of ways, each of on the basis of one or more disaggregation methods.\n\nEach row in the table indicates the data features available for each segment/method combination (Segment, Disaggregation method).\nStructure incidates whether the data support cross-sectional (CS) or time-series cross-sectional (TSCS) analysis. In the case of TSCS data, Unit indicates the smallest level of disaggregation available (M for months).\nEfficiency indicates whether it is currently possible to calculate the proportion or share of research projects that meet the definition of lifecycle open science for each segment/method combination (Y for yes, N for no).\n\n\n\n\n\n\n\n\n\n\n\nSegment\nDisaggregation method\nStructure\nUnit\nEfficiency\n\n\n\n\nAggregate\n-\nTSCS\nM\nY\n\n\nOSFI\nDichotomous\n\n\n\n\n\nOSFI\nCategorical\n\n\n\n\n\nSubjects\nAggregate (parent subjects)\n\n\n\n\n\nSubjects\nDetailed (child subjects)\n\n\n\n\n\nProvider\nCategorical\n\n\n\n\n\nCreator demographics\nAge cohort"
  },
  {
    "objectID": "scripts/project/001-preprint_assertions.html#methodology",
    "href": "scripts/project/001-preprint_assertions.html#methodology",
    "title": "Recipe 001: Preprint Assertions",
    "section": "Methodology",
    "text": "Methodology\nWe can use the osf_preprint table and relevant actions in the osf_preprintlog table to determine when linked datasets and preregistrations were first added to the preprint.\nTo get at when a preprint gets linked datasets and/or preregistrations added to it, we need to look for the has_data_links_updated and has_prereg_links_updated action types in the osf_preprintlog table.\nIf a preprint has no assertion actions in the log table BUT has corresponding flag values set to TRUE in the osf_preprint table, we assume the preprint contained the links at the time of creation (created).\nWe can combine this new information with the datasets previously created in open-preprints to create a time series of lifecycle open research projects."
  },
  {
    "objectID": "scripts/project/001-preprint_assertions.html#implementation",
    "href": "scripts/project/001-preprint_assertions.html#implementation",
    "title": "Recipe 001: Preprint Assertions",
    "section": "Implementation",
    "text": "Implementation\n\n\nSee the code\nLOS_CRITERIA &lt;- rlang::exprs(\n    !is.na(date_published),\n    !is.na(date_public),\n    is.na(deleted),\n    is.na(date_withdrawn),\n    !is.na(date_data),\n    !is.na(date_prereg),\n)\n\n# Actions of interest\nOPEN_ACTIONS &lt;- c(\"has_data_links_updated\", \"has_prereg_links_updated\")\n\n# Load tables\npreprint_tbl &lt;- open_parquet(tbl = \"osf_preprint\") |&gt;\n    select(id, created, has_data_links, has_prereg_links) \npplog_tbl &lt;- open_parquet(tbl = \"osf_preprintlog\") |&gt;\n    select(preprint_id, action, created) |&gt;\n    filter(action %in% OPEN_ACTIONS)\nlos_preprint &lt;- open_dataset(here::here(\"data\", \"preprints.parquet\"))\n\n# Date(s) of first open actions among preprints that MAY NOT have always had them\nlogged_preprints &lt;- pplog_tbl |&gt;\n    to_duckdb() |&gt;\n    summarise(\n        .by = c(preprint_id, action),\n        action_date = min(created)\n    ) |&gt;\n    select(preprint_id, action, action_date) |&gt;\n    to_arrow() |&gt;\n    mutate(\n        action = case_when(\n            action == \"has_data_links_updated\" ~ \"date_data\",\n            action == \"has_prereg_links_updated\" ~ \"date_prereg\"\n        )\n    ) |&gt;\n    collect() |&gt;\n    pivot_wider(\n        names_from = action,\n        values_from = action_date\n    ) \n\n# Rise and repeat for preprints that have ALWAYS had them\nalways_data_preprints &lt;- preprint_tbl |&gt;\n    filter(has_data_links == \"available\") |&gt;\n    select(id, created) |&gt;\n    anti_join(logged_preprints, by = c(\"id\" = \"preprint_id\")) |&gt;\n    rename(\n        preprint_id = id,\n        date_data = created\n    )\nalways_prereg_preprints &lt;- preprint_tbl |&gt;\n    filter(has_prereg_links == \"available\") |&gt;\n    select(id, created) |&gt;\n    anti_join(logged_preprints, by = c(\"id\" = \"preprint_id\")) |&gt;\n    rename(\n        preprint_id = id,\n        date_prereg = created\n    )\nalways_preprints &lt;- always_data_preprints |&gt;\n    left_join(\n        always_prereg_preprints,\n        by = \"preprint_id\"\n    ) \n\n# Combine\nall_preprints &lt;- bind_rows(\n    logged_preprints,\n    collect(always_preprints)\n    )\n\n# Now, let's create a new table for LOS projects\nlos_projects &lt;- los_preprint |&gt;\n    collect() |&gt;\n    left_join(all_preprints, by = c(\"id\" = \"preprint_id\"))\n\n# We also want to add the latest of all required actions and linkages to determine when (if at all) the project achieved LOS status\nlos_projects &lt;- los_projects |&gt;\n    mutate(\n        date_los = max(date_published, date_public, date_data, date_prereg, na.rm = TRUE),\n        date_los = ifelse(\n            !is.na(date_published) | !is.na(date_public) | !is.na(date_data) | !is.na(date_prereg) &gt; 0, NA, date_los\n        ),\n        date_los_valid = case_when(\n            !is.na(deleted) | !is.na(date_withdrawn) ~ NA,\n            TRUE ~ date_los\n        )\n    )\n\n# Quick check of observations\nnrow(los_projects) == nrow(preprint_tbl)\n\n\n[1] TRUE\n\n\nSee the code\n# Write to parquet\nwrite_parquet(los_projects, here::here(\"data\", \"los_001_pass.parquet\"))"
  },
  {
    "objectID": "scripts/project/001-preprint_assertions.html#aggregate-time-series",
    "href": "scripts/project/001-preprint_assertions.html#aggregate-time-series",
    "title": "Recipe 001: Preprint Assertions",
    "section": "Aggregate time series",
    "text": "Aggregate time series\n\n\nSee the code\n# Set time span\nTIMESPAN &lt;- c(\"2018-01-01\", \"2025-06-01\")\nDELTA &lt;- \"month\"\nDATES &lt;- seq(as.POSIXct(TIMESPAN[1]), as.POSIXct(TIMESPAN[2]), by = DELTA)\n\n\n\n\nSee the code\nlos_summary &lt;- purrr::map(\n    DATES, \n    ~ los_projects |&gt;\n    filter(created &lt;= .x) |&gt;\n    summarise(\n        n_total = n(),\n        n_deleted = sum(!is.na(deleted)),\n        n_withdrawn = sum(!is.na(date_withdrawn)),\n        n_valid = sum(is.na(date_withdrawn) & is.na(deleted)),\n        # individually open components\n        n_open_preprint = sum(!is.na(date_published) & !is.na(date_public)),\n        n_open_data = sum(!is.na(date_data)),\n        n_open_prereg = sum(!is.na(date_prereg)),\n        # paired open components\n        n_open_data_prereg = sum(!is.na(date_data) & !is.na(date_prereg)),\n        n_open_preprint_data = sum(!is.na(date_published) & !is.na(date_public) & !is.na(date_data)),\n        n_open_preprint_prereg = sum(!is.na(date_published) & !is.na(date_public) & !is.na(date_prereg)),\n        # full life cycle open\n        n_los = sum(!is.na(date_los)),\n        n_los_valid = sum(!is.na(date_los_valid)),\n    ) |&gt;\n    mutate(\n        n_mos = n_open_data_prereg + n_open_preprint_data + n_open_preprint_prereg,  #mos = \"mostly open\" (2/3)\n        n_pos = n_open_preprint + n_open_data + n_open_prereg,  #pos = \"partially open\" (1/3)\n        pct_valid = n_valid / n_total,\n        los_efficiency = n_los / n_total,\n        los_efficiency_valid = n_los_valid / n_valid\n    ),\n    .progress = TRUE) |&gt;\n    set_names(DATES) |&gt;\n    list_rbind(names_to = \"date\")\n\n# Save\nwrite_parquet(los_projects, here::here(\"data\", \"los_001_pass_summary.parquet\"))"
  },
  {
    "objectID": "scripts/component/open-preprints.html",
    "href": "scripts/component/open-preprints.html",
    "title": "OSF Preprints",
    "section": "",
    "text": "This module examines candidacy criteria for open science among OSF Preprints.\n\n\n\nWe define an open preprint as one that meets the following criteria:\n\nPublished\nPublic\nNot deleted\nNot withdrawn\n\n\n\n\nThe following table indicates the data features currently suported for these analyses.\nThe data can be segmented in a variety of ways, each of on the basis of one or more disaggregation methods.\n\nEach row in the table indicates the data features available for each segment/method combination (Segment, Disaggregation method).\n\nStructure incidates whether the data support cross-sectional (CS) or time-series cross-sectional (TSCS) analysis. In the case of TSCS data, Unit indicates the smallest level of disaggregation available (M for months). -Efficiency indicates whether it is currently possible to calculate the proportion or share of research projects that meet the definition of lifecycle open science for each segment/method combination (Y for yes, N for no).\n\n\n\n\n\n\n\n\n\n\n\nSegment\nDisaggregation method\nStructure\nUnit\nEfficiency\n\n\n\n\nAggregate\n-\nTSCS\nM\nY\n\n\nOSFI\nDichotomous\n\n\n\n\n\nOSFI\nCategorical\n\n\n\n\n\nSubjects\nAggregate (parent subjects)\nTSCS\nM\nY\n\n\nSubjects\nDetailed (child subjects)\n\n\n\n\n\nProvider\nCategorical\n\n\n\n\n\nCreator demographics\nAge cohort"
  },
  {
    "objectID": "scripts/component/open-preprints.html#definition",
    "href": "scripts/component/open-preprints.html#definition",
    "title": "OSF Preprints",
    "section": "",
    "text": "We define an open preprint as one that meets the following criteria:\n\nPublished\nPublic\nNot deleted\nNot withdrawn"
  },
  {
    "objectID": "scripts/component/open-preprints.html#current-features",
    "href": "scripts/component/open-preprints.html#current-features",
    "title": "OSF Preprints",
    "section": "",
    "text": "The following table indicates the data features currently suported for these analyses.\nThe data can be segmented in a variety of ways, each of on the basis of one or more disaggregation methods.\n\nEach row in the table indicates the data features available for each segment/method combination (Segment, Disaggregation method).\n\nStructure incidates whether the data support cross-sectional (CS) or time-series cross-sectional (TSCS) analysis. In the case of TSCS data, Unit indicates the smallest level of disaggregation available (M for months). -Efficiency indicates whether it is currently possible to calculate the proportion or share of research projects that meet the definition of lifecycle open science for each segment/method combination (Y for yes, N for no).\n\n\n\n\n\n\n\n\n\n\n\nSegment\nDisaggregation method\nStructure\nUnit\nEfficiency\n\n\n\n\nAggregate\n-\nTSCS\nM\nY\n\n\nOSFI\nDichotomous\n\n\n\n\n\nOSFI\nCategorical\n\n\n\n\n\nSubjects\nAggregate (parent subjects)\nTSCS\nM\nY\n\n\nSubjects\nDetailed (child subjects)\n\n\n\n\n\nProvider\nCategorical\n\n\n\n\n\nCreator demographics\nAge cohort"
  },
  {
    "objectID": "scripts/component/open-preprints.html#methodology",
    "href": "scripts/component/open-preprints.html#methodology",
    "title": "OSF Preprints",
    "section": "Methodology",
    "text": "Methodology\nWe can use the date variables in the osf_preprint table and related actions in the osf_preprintlog table to generate a time series of lifecycle open preprints.\nFrom the osf_preprint table, we already know when the following actions occured:\n\ncreated\ndate_published\ndate_withdrawn\ndeleted\n\nTo get at when a preprint became public (as well as possible reversions to private status), we need to look for the made_public and made_private action types in the osf_preprintlog table.\nIf a preprint has no visibility actions in the log table BUT has is_public == TRUE in the osf_preprint table, we assume the preprint was made public at the time of creation (created)"
  },
  {
    "objectID": "scripts/component/open-preprints.html#implementation",
    "href": "scripts/component/open-preprints.html#implementation",
    "title": "OSF Preprints",
    "section": "Implementation",
    "text": "Implementation\n\n\nSee the code\n# Packages\nlibrary(arrow)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(tidyr)\nlibrary(purrr)\n\n# Places\nPQDIR &lt;- \"~/osfdata/parquet\"\n\n# Helper functions\nopen_parquet &lt;- function(dir = PQDIR, tbl) {\n    arrow::open_dataset(file.path(dir, paste0(tbl, \".parquet\")))\n}\nget_parquet_info &lt;- function(dir = PQDIR, tbl) {\n    nanoparquet::read_parquet_info(file.path(dir, paste0(tbl, \".parquet\")))\n}\n\n\n\n\nSee the code\n# Criteria\nPREPRINT_CRITERIA &lt;- rlang::exprs(\n    !is.na(date_published),\n    !is.na(date_public),\n    is.na(deleted),\n    is.na(date_withdrawn)\n    )\n\n# Actions of interest to determine *if/when* preprints became public\nPUBLIC_ACTIONS &lt;- c(\"made_public\")\nPRIVATE_ACTIONS &lt;- c(\"made_private\")\n\n# Load tables\npreprint_tbl &lt;- open_parquet(tbl = \"osf_preprint\") |&gt;\n    select(id, is_public, is_published, created, date_published, date_withdrawn, deleted)\n\npplog_tbl &lt;- open_parquet(tbl = \"osf_preprintlog\") |&gt;\n    select(preprint_id, action, created) |&gt;\n    filter(action %in% c(PUBLIC_ACTIONS, PRIVATE_ACTIONS))\n\n\nWe create two new tables, one to capture the preprints that have always been public and another to focus in the preprints whose logged actions could incidicate potential changes in visibility over time.\nWe will be able to set the value of a new variable, date_public for all preprints that have always been public. For the other preprints with relevant logged actions, the value of date_public will be the date of the most recent logged action defined in PUBLIC_ACTIONS (i.e. made_public).\n\n\nSee the code\n# Date of public visibility among preprints that MAY NOT have always been public\nlogged_preprints &lt;- pplog_tbl |&gt;\n    to_duckdb() |&gt;\n    summarise(\n        .by = preprint_id,\n        last_action_date = max(created),\n        last_action = last(action),\n    ) |&gt;\n    mutate(\n        date_public = ifelse(\n            last_action %in% PUBLIC_ACTIONS,\n            last_action_date,\n            NA\n        )\n    ) |&gt;\n    select(preprint_id, date_public) |&gt;\n    to_arrow()\n\n# Rise and repeat for preprints that have ALWAYS been public\nalways_preprints &lt;- preprint_tbl |&gt;\n    filter(is_public) |&gt;\n    select(id, created) |&gt;\n    anti_join(logged_preprints, by = c(\"id\" = \"preprint_id\")) |&gt;\n    rename(\n        preprint_id = id,\n        date_public = created\n    )\n\n# Combine\nall_preprints &lt;- bind_rows(\n    collect(always_preprints),\n    collect(logged_preprints)\n    )\n\n# Now, let's create a new table for LOS preprints\nlos_preprints &lt;- preprint_tbl |&gt;\n    select(id, date_published, date_withdrawn, created, deleted) |&gt;\n    collect() |&gt;\n    left_join(all_preprints, by = c(\"id\" = \"preprint_id\"))\n\n# Quick check of observations\nnrow(los_preprints) == nrow(preprint_tbl)\n\n\n[1] TRUE\n\n\nSee the code\n# Write to parquet\nwrite_parquet(los_preprints, here::here(\"data\", \"preprints.parquet\"))"
  },
  {
    "objectID": "scripts/component/open-preprints.html#aggregate-time-series",
    "href": "scripts/component/open-preprints.html#aggregate-time-series",
    "title": "OSF Preprints",
    "section": "Aggregate time series",
    "text": "Aggregate time series\nWe first summarize preprints by various openness criteria over time.\n\n\nSee the code\n# Set time span\nTIMESPAN &lt;- c(\"2018-01-01\", \"2025-06-01\")\nDELTA &lt;- \"month\"\nDATES &lt;- seq(as.POSIXct(TIMESPAN[1]), as.POSIXct(TIMESPAN[2]), by = DELTA)\n\n\nSpecifically, we compute the following sums for each year-month in the time series:\n\nn_total: All preprints created on or before this date\nn_public: Number of public preprints\nn_published: Number of published preprints\nn_withdrawn: Number of withdrawn preprints\nn_deleted: Number of preprints deleted on or before this date\nn_valid: Number of valid preprints (i.e., not deleted or withdrawn)\nn_open: Number of preprints that are both published and public on or before a given date (i.e., union of n_published and n_public)\nn_open_valid: Number of preprints that both open and valid on or before a given date (i.e., union of n_open and n_valid)\n\nThen, we derive the following quantities of interest from these sums:\n\npct_valid: Proportion of valid preprints (i.e., not deleted or withdrawn) created on or before this date that are not deleted or withdrawn\nopen_efficiency: Proportion of all preprints that are both published and public on or before this date\nopen_efficiency_valid: Proportion of valid preprints that are both published and public on or before this date\n\n\n\nSee the code\nstate_summary &lt;- purrr::map(\n    DATES,\n    ~los_preprints |&gt;\n        filter(created &lt;= .x) |&gt;\n        summarise(\n            n_total = n(),\n            n_public = sum(!is.na(date_public)),\n            n_published = sum(!is.na(date_published)),\n            n_withdrawn = sum(!is.na(date_withdrawn)),\n            n_deleted = sum(!is.na(deleted)),\n            n_valid = sum(is.na(date_withdrawn) & is.na(deleted)),\n            n_open = sum(!is.na(date_published) & !is.na(date_public)),\n            n_open_valid = sum(!is.na(date_published) & !is.na(date_public) & is.na(date_withdrawn) & is.na(deleted)),\n        ) |&gt;\n        mutate(\n            pct_valid = n_valid / n_total,\n            open_efficiency = n_open / n_total,\n            open_efficiency_valid = n_open_valid / n_valid\n        ),\n    .progress = TRUE) |&gt;\n    set_names(DATES) |&gt;\n    list_rbind(names_to = \"date\")\n\n# Save\nwrite_parquet(state_summary, here::here(\"data\", \"preprint_summary.parquet\"))"
  },
  {
    "objectID": "scripts/component/open-preprints.html#aggregate-results",
    "href": "scripts/component/open-preprints.html#aggregate-results",
    "title": "OSF Preprints",
    "section": "Aggregate results",
    "text": "Aggregate results\nNow, we plot the relationship between these quantities over time.\n\n\nSee the code\nstate_summary_long &lt;- state_summary |&gt;\n    pivot_longer(\n        cols = starts_with(\"n_\"),\n        names_to = \"state\",\n        names_prefix = \"n_\",\n        values_to = \"n\"\n    )\n    \nstate_summary_long |&gt;\n    filter(state %in% c(\"total\", \"valid\", \"open\", \"open_valid\")) |&gt;\n    mutate(state = factor(state, levels = c(\"total\", \"valid\", \"open\", \"open_valid\"))) |&gt;\n    ggplot(aes(x = as.Date(date), y = n, group = state, color = state)) + \n    geom_line() +\n    theme_minimal() +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    scale_y_continuous(labels = scales::comma) +\n    labs(y = \"Number of preprints\", x = \"Date\") +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nWe can also visualze the efficiencies over time.\n\n\nSee the code\nstate_summary |&gt;\n    pivot_longer(\n        cols = starts_with(\"open_\"),\n        names_to = \"state\",\n        names_prefix = \"open_\",\n        values_to = \"p\"\n    ) |&gt;\n    filter(grepl(\"efficiency\", state)) |&gt;\n    mutate(state = factor(state, levels = c(\"efficiency\", \"efficiency_valid\"))) |&gt;\n    ggplot(aes(x = as.Date(date), y = p, group = state, color = state)) +\n    geom_line() +\n    theme_minimal() +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    scale_y_continuous(labels = scales::percent) +\n    labs(y = \"Efficiency\", x = \"Date\") +\n    theme(legend.position = \"bottom\", legend.title = element_blank())"
  },
  {
    "objectID": "scripts/component/open-preprints.html#faceting-by-subject",
    "href": "scripts/component/open-preprints.html#faceting-by-subject",
    "title": "OSF Preprints",
    "section": "Faceting by subject",
    "text": "Faceting by subject\nWe can also plot the distribution of subjects over time among, total, valid, and open preprints. To ease interpretation, we focus on “top-level” subject fields and restrict the analysis to subjects representing at least 5% of all preprints.\n\n\nSee the code\nsubjects_tbl &lt;- open_dataset(here::here(\"data\", \"preprint_subjects.parquet\")) |&gt;\n    filter(is.na(parent_id)) |&gt;\n    mutate(subject_text = ifelse(is.na(subject_text), \"None\", subject_text))\npreprints_tbl &lt;- open_dataset(here::here(\"data\", \"preprints.parquet\"))\n\n# Combine\npreprints_with_subjects &lt;- preprints_tbl |&gt;\n    left_join(subjects_tbl, by = c(\"id\" = \"preprint_id\")) |&gt;\n    select(-subject_id, -parent_id) \n\n# Get distribution of subjects among preprints\nsubject_distribution &lt;- preprints_with_subjects |&gt;\n    to_duckdb() |&gt;\n    summarise(\n        .by = subject_text,\n        n = n(),\n        first_created = min(created),\n        first_valid = min(created[is.na(date_withdrawn) & is.na(deleted)])\n    ) |&gt;\n    mutate(prop = n / sum(n)) |&gt;\n    collect() \n\n# Subjects corresponding at at least 5% of all preprints\nsubjects &lt;- subject_distribution |&gt;\n    filter(prop &gt;= 0.05) |&gt;\n    pull(subject_text)\n\nsubject_summary &lt;- purrr::map(\n    .x = DATES,\n    ~ preprints_with_subjects |&gt;\n        filter(created &lt;= .x & subject_text %in% subjects) |&gt;\n        to_duckdb() |&gt;\n        summarise(\n            .by = subject_text,\n            n_total = n(),\n            n_valid = sum(is.na(date_withdrawn) & is.na(deleted)),\n            n_open = sum(!is.na(date_published) & !is.na(date_public)),\n            n_open_valid = sum(!is.na(date_published) & !is.na(date_public) & is.na(date_withdrawn) & is.na(deleted)),\n        ) |&gt;\n        mutate(\n            pct_valid = n_valid / n_total,\n            open_efficiency = n_open / n_total,\n            open_efficiency_valid = n_open_valid / n_valid\n        ) |&gt;\n        collect(),\n    .progress = TRUE) |&gt;\n    set_names(DATES) |&gt;\n    list_rbind(names_to = \"date\") \n\n\nNow we can plot the distribution of subjects over time among, total, valid, and open preprints.\n\n\nSee the code\nplot_tbl &lt;- subject_summary |&gt;\n    select(date, subject_text, n_total, n_valid, n_open, n_open_valid) |&gt;\n    pivot_longer(\n        cols = starts_with(\"n_\"),\n        names_to = \"state\",\n        names_prefix = \"n_\",\n        values_to = \"n\"\n    ) |&gt;\n    mutate(state = factor(state, levels = c(\"total\", \"valid\", \"open\", \"open_valid\")))\n\nplot_tbl |&gt;\n    ggplot(aes(x = as.Date(date), y = n, group = state, color = state)) + \n    geom_line() +\n    theme_minimal() +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    scale_y_continuous(labels = scales::comma) +\n    facet_wrap(~subject_text, scales = \"free_y\") +\n    labs(y = \"Number of preprints\", x = \"Date\") +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nWe can also compare the efficiencies.\n\n\nSee the code\nplot_tbl &lt;- subject_summary |&gt;\n    select(date, subject_text, open_efficiency, open_efficiency_valid) |&gt;\n    pivot_longer(\n        cols = starts_with(\"open_\"),\n        names_to = \"efficiency\",\n        names_prefix = \"open_\",\n        values_to = \"p\"\n    ) \n\nplot_tbl |&gt;\n    ggplot(aes(x = as.Date(date), y = p, color = subject_text, group = subject_text)) +\n    geom_line() +\n    theme_minimal() +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    scale_y_continuous(labels = scales::percent) +\n    facet_wrap(~efficiency) +\n    labs(y = \"Efficiency\", x = \"Date\") +\n    theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "scripts/component/open-registrations.html",
    "href": "scripts/component/open-registrations.html",
    "title": "OSF Registrations",
    "section": "",
    "text": "This vignette examines candidacy criteria for lifecycle open science among OSF Registrations.\nCandidate registrations meet standards for and openness, non-deprecation, authenticity. Specifically, an open-science registraiton must be:\nOpen\n\nPublic (open-1)\nNot embargoed (open-2)\n\nNon-deprecated\n\nRegistered (nondeprecated-1)\nNot deleted (nondeprecated-2)\nNot retracted (nondeprecated-3)\n\nAuthentic\n\nNot spam (authentic-1)\n\n\n\nWe can use the date variables from the registration dataset and relevant actions from the osf_nodelog table to generate a time series dataset of OSF Registrations.\nFrom the osf_abstractnode table, we already know when the following actions occured:\n\ncreated\nregistered_date\ndeleted\n\nTo establish when a registration becomes:\n\npublic, we need to look for the made_public and made_private action types in the osf_nodelog table.\n\n(un)embargoed, we need to look for corresponding actions with the embargo_ prefix in the osf_nodelog table.\nretracted, we will look for corresponding actions with the retraction_ prefix in the osf_nodelog table.\nspam, we look for the actions of type confirm_spam in the osf_nodelog table.\n\nFor every criteria of interest (i.e., public, non-embargoed, registered, non-deleted, non-retracted, non-spam), if we cannot find a corresponding action in the osf_nodelog table, we will assume that the criteria is met at the time of creation (created).\n\n\n\n\nNOTE: These will be made available soon!\n\nSee registrations.r and registration-ts.r for the bulk of the implementation details. For now, we just load the datasets we need.\n\n\nSee the code\n# Packages\nlibrary(arrow)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(rlang)\nlibrary(timetk)\nlibrary(gt)\n\n# Modules\nbox::use(\n    R / connect[open_parquet],\n    R / helpers[tidy_registry_names],\n    R / plot[pivoter, factorizer, ts_prep]\n)\n\n# Data sources\nall_ts &lt;- read_parquet(here::here(\"data/registration_tsmonthly.parquet\"))\nregistry_ts &lt;- read_parquet(here::here(\"data/registration_registries_tsmonthly.parquet\")) |&gt;\n    mutate(registry = tidy_registry_names(registry))\n\n# Pivot for plots and assign labels\nall_summary &lt;- pivoter(all_ts) |&gt;\n    ts_prep()\nregistry_summary &lt;- pivoter(registry_ts, registry) |&gt;\n    ts_prep()\n\n# Constants\nMOST_RECENT_CHR &lt;- max(all_ts$date)\nMOST_RECENT &lt;- ymd(MOST_RECENT_CHR)\nTABLE_CRITERIA &lt;- c(\n    \"total\", \"open\", \"not_deprecated\", \"authentic\",\n    \"open_notdep\", \"open_auth\", \"notdep_auth\",\n    \"los_plan\")\nTABLE_NAMES &lt;- c(\n    \"Total\", \"Open\", \"Non-deprecated\", \"Authentic\",\n    \"Open + Non-deprecated\", \"Open + Authentic\", \"Non-deprecated + Authentic\",\n    \"Open Science Registration\")"
  },
  {
    "objectID": "scripts/component/open-registrations.html#operationalization",
    "href": "scripts/component/open-registrations.html#operationalization",
    "title": "OSF Registrations",
    "section": "",
    "text": "We can use the date variables from the registration dataset and relevant actions from the osf_nodelog table to generate a time series dataset of OSF Registrations.\nFrom the osf_abstractnode table, we already know when the following actions occured:\n\ncreated\nregistered_date\ndeleted\n\nTo establish when a registration becomes:\n\npublic, we need to look for the made_public and made_private action types in the osf_nodelog table.\n\n(un)embargoed, we need to look for corresponding actions with the embargo_ prefix in the osf_nodelog table.\nretracted, we will look for corresponding actions with the retraction_ prefix in the osf_nodelog table.\nspam, we look for the actions of type confirm_spam in the osf_nodelog table.\n\nFor every criteria of interest (i.e., public, non-embargoed, registered, non-deleted, non-retracted, non-spam), if we cannot find a corresponding action in the osf_nodelog table, we will assume that the criteria is met at the time of creation (created)."
  },
  {
    "objectID": "scripts/component/open-registrations.html#implementation",
    "href": "scripts/component/open-registrations.html#implementation",
    "title": "OSF Registrations",
    "section": "",
    "text": "NOTE: These will be made available soon!\n\nSee registrations.r and registration-ts.r for the bulk of the implementation details. For now, we just load the datasets we need.\n\n\nSee the code\n# Packages\nlibrary(arrow)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(rlang)\nlibrary(timetk)\nlibrary(gt)\n\n# Modules\nbox::use(\n    R / connect[open_parquet],\n    R / helpers[tidy_registry_names],\n    R / plot[pivoter, factorizer, ts_prep]\n)\n\n# Data sources\nall_ts &lt;- read_parquet(here::here(\"data/registration_tsmonthly.parquet\"))\nregistry_ts &lt;- read_parquet(here::here(\"data/registration_registries_tsmonthly.parquet\")) |&gt;\n    mutate(registry = tidy_registry_names(registry))\n\n# Pivot for plots and assign labels\nall_summary &lt;- pivoter(all_ts) |&gt;\n    ts_prep()\nregistry_summary &lt;- pivoter(registry_ts, registry) |&gt;\n    ts_prep()\n\n# Constants\nMOST_RECENT_CHR &lt;- max(all_ts$date)\nMOST_RECENT &lt;- ymd(MOST_RECENT_CHR)\nTABLE_CRITERIA &lt;- c(\n    \"total\", \"open\", \"not_deprecated\", \"authentic\",\n    \"open_notdep\", \"open_auth\", \"notdep_auth\",\n    \"los_plan\")\nTABLE_NAMES &lt;- c(\n    \"Total\", \"Open\", \"Non-deprecated\", \"Authentic\",\n    \"Open + Non-deprecated\", \"Open + Authentic\", \"Non-deprecated + Authentic\",\n    \"Open Science Registration\")"
  },
  {
    "objectID": "scripts/component/open-registrations.html#all-registrations",
    "href": "scripts/component/open-registrations.html#all-registrations",
    "title": "OSF Registrations",
    "section": "All Registrations",
    "text": "All Registrations\n\nNOTE: All graphs are interactive. Click on the legend to toggle series on/off. You can also use the slider to scroll through the timerange. Zooming is also supported.\n\nThe following plots show the distribution of registrations along multiple (sub)criteria of interest. The total number of registrations (i.e., all registrations in the database wihthout any filtering) is shown in black.\nThe following graph plots the distribution of registrations along the six different sub-criteria of interest denoted at the beginning. Registrations can be duplicated across criteria. The total number of registrations is shown in black.\n\n\nSee the code\nall_summary |&gt;\n    factorizer(criteria) |&gt;\n    plot_time_series(date, n, .color_var = criteria, .smooth = FALSE,\n    .title = \"OSF Registrations by Open Science Subcriteria\")\n\n\n\n\n\n\nThe next figure plots the distribution of registrations according to the three main criteria of interest (i.e., Open, Non-deprecated, Authentic). Plus signs (+) indicate registrations that jointly satisfy 2 or more criteria. The “Open Science Registration” line plots the number of registrations meeting all 3 criteria.\n\n\nSee the code\nall_summary |&gt;\n    factorizer(criteria, 2) |&gt;\n    plot_time_series(date, n, .color_var = criteria, .smooth = FALSE,\n    .title = \"OSF Registrations by Open Science Criteria\")\n\n\n\n\n\n\nThe next graph is just a simplified version of the previous one, where we only show registrations that jointly satisfy 2 or more criteria. The “Total” line is included for reference.\n\n\nSee the code\nall_summary |&gt; \n    factorizer(criteria, 3) |&gt;\n    plot_time_series(date, n, .color_var = criteria, .smooth = FALSE,\n    .title = \"OSF Registrations with 2+ Open Science Criteria\")"
  },
  {
    "objectID": "scripts/component/open-registrations.html#summary-by-registry",
    "href": "scripts/component/open-registrations.html#summary-by-registry",
    "title": "OSF Registrations",
    "section": "Summary by Registry",
    "text": "Summary by Registry\n\n\nSee the code\nregistry_tbl &lt;- registry_summary |&gt;\n    filter(criteria %in% TABLE_CRITERIA) |&gt;\n    pivot_wider(id_cols = c(date, registry), names_from = criteria, values_from = n)\ncolnames(registry_tbl) &lt;- c(\"Date\", \"Registry\", TABLE_NAMES)\n\nregistry_tbl &lt;- registry_tbl |&gt;\n    select(Date, Registry, Total, starts_with(\"Open\")) |&gt;\n    mutate(\n        `OSR / Open` = `Open Science Registration` / Open,\n        `OSR / Total` = `Open Science Registration` / Total)\n\nregistry_gtbl &lt;- registry_tbl |&gt;\n    ungroup() |&gt;\n    filter(Date == MOST_RECENT) |&gt;\n    arrange(desc(`Open Science Registration`)) |&gt;\n    select(-Date) |&gt;\n    gt() |&gt;\n    tab_header(\n        title = \"Open Science Registrations by Registry\",\n        subtitle = paste0(\"as of \", MOST_RECENT_CHR)) |&gt;\n    fmt_number(columns = c(Total:`Open Science Registration`), decimals = 0) |&gt;\n    fmt_percent(columns = c(`OSR / Open`, `OSR / Total`), decimals = 1) \n\n\nHere’s a summary table of OSF Registrations by Registry:\n\nTotal: Total number of OSF Registrations (no filtering at all)\nOpen: Number of registrations that are public and not embargoed\nOpen + Non-deprecated: Number of registrations that are Open and are registered, not deleted, and not retracted\nOpen + Authentic: Number of registrations that are Open and are not spam\nOpen Science Registration: Number of registrations meeting all three criteria (i.e., Open + Non-deprecated + Authentic)\nOSR / Open: Percentage of Open (i.e., public and not embargoed) registrations that meet the Open Science Registration criteria\nOSR / Total: Percentage of Total registrations that meet the Open Science Registration criteria\n\n\n\nSee the code\nregistry_gtbl\n\n\n\n\n\n\n\n\nOpen Science Registrations by Registry\n\n\nas of 2025-08-01\n\n\nRegistry\nTotal\nOpen\nOpen + Non-deprecated\nOpen + Authentic\nOpen Science Registration\nOSR / Open\nOSR / Total\n\n\n\n\nOSF\n281,156\n167,803\n158,386\n165,020\n156,011\n93.0%\n55.5%\n\n\nEGAP\n2,969\n2,333\n2,317\n2,308\n2,292\n98.2%\n77.2%\n\n\nCharacter Lab\n448\n448\n447\n433\n432\n96.4%\n96.4%\n\n\nDAM\n152\n121\n120\n120\n119\n98.3%\n78.3%\n\n\nGFS\n494\n106\n104\n106\n104\n98.1%\n21.1%\n\n\nReal World Evidence\n155\n88\n81\n88\n81\n92.0%\n52.3%\n\n\nDARPA ASIST\n112\n60\n60\n56\n56\n93.3%\n50.0%\n\n\nYOUth Study\n61\n54\n53\n54\n53\n98.1%\n86.9%\n\n\nOSF Data Archive\n49\n26\n24\n25\n23\n88.5%\n46.9%\n\n\nTWCF Consciousness Studies\n29\n23\n21\n22\n20\n87.0%\n69.0%\n\n\nMetascience\n21\n15\n13\n15\n13\n86.7%\n61.9%\n\n\nOSPD Workflow and Results Hub\n23\n13\n11\n12\n10\n76.9%\n43.5%\n\n\nLifecycle Journal\n19\n12\n6\n12\n6\n50.0%\n31.6%\n\n\nState of North Carolina\n6\n5\n5\n4\n4\n80.0%\n66.7%\n\n\n\n\n\n\n\nWe can also plot these numbers over time for each registry. Because of the disparity in the number of registrations between registries, we calculate the percentage of registrations that meeting Open Science Registration criteria. This are the OSR / Open and OSR / Total metrics from the previous table.\n\n\nSee the code\n# Prep\nregistry_ptbl &lt;- registry_tbl |&gt;\n    select(Date, Registry, `OSR / Open`, `OSR / Total`) |&gt;\n    pivot_longer(\n        cols = c(`OSR / Open`, `OSR / Total`),\n        names_to = \"Metric\", values_to = \"Percentage\") |&gt;\n    ungroup()\n\n# First plot\nregistry_ptbl |&gt;\n    filter(Metric == \"OSR / Open\") |&gt;\n    plot_time_series(Date, Percentage, .color_var = Registry,\n    .smooth = FALSE, .title = \"Open Efficiency of OSF Registrations by Registry\")\n\n\n\n\n\n\n\n\nSee the code\n# Second plot\nregistry_ptbl |&gt;\n    filter(Metric == \"OSR / Total\") |&gt;\n    plot_time_series(Date, Percentage, .color_var = Registry,\n    .smooth = FALSE, .title = \"Total Efficiency of OSF Registrations by Registry\")"
  }
]